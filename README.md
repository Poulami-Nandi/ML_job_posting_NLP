# ML Job Postings NLP Project

## ğŸ“„ Project Overview
This project applies Natural Language Processing (NLP) techniques to analyze 1,000 machine learning job postings across the United States. The analysis includes topic modeling, sentiment analysis, named entity recognition, trend detection, and interactive dashboarding.

## ğŸ¯ Objectives
- Extract and analyze dominant topics in job descriptions.
- Understand sentiment trends and tone in job postings.
- Extract skills and named entities using NER.
- Visualize job trends over time, regions, companies, and seniority.
- Build an interactive exploratory dashboard inside the notebook.

## ğŸ—‚ Dataset
- **Source**: Proprietary dataset of 1,000 ML job postings.
- **Columns**:
  - `job_posted_date`
  - `company_address_locality`
  - `company_address_region`
  - `company_name`
  - `company_website`
  - `company_description`
  - `job_description_text`
  - `seniority_level`
  - `job_title`

## ğŸ”§ Tools & Libraries
- Python 3
- Pandas, Numpy
- Scikit-learn (LDA, Clustering)
- TextBlob (Sentiment Analysis)
- spaCy (NER)
- UMAP-learn, TSNE (Clustering visualization)
- Matplotlib, Seaborn, Plotly
- WordCloud
- Ipywidgets (Dashboard)

## Project Layout
```bash
ML_job_posting_NLP/
â”‚
â”œâ”€â”€ data/                         # ğŸ“ Raw and processed datasets
â”‚   â”œâ”€â”€ 1000_ml_jobs_us.csv
â”‚   â””â”€â”€ sample_ml_job_postings.csv
â”‚
â”œâ”€â”€ notebooks/                    # ğŸ“ Jupyter/Google colab notebooks
â”‚   â”œâ”€â”€ NLP_ML_Job_Postings.ipynb
â”‚
â”œâ”€â”€ dashboard/                    # ğŸ“ Dashboard code (ipywidgets and Streamlit)
â”‚   â”œâ”€â”€ dashboard_widgets.py
â”‚   â””â”€â”€ dashboard_streamlit.py 
â”‚
â”œâ”€â”€ reports/                      # ğŸ“ Reports, insights, presentation material
â”‚   â””â”€â”€ insights_summary.pdf 
â”‚
â”œâ”€â”€ visuals/                      # ğŸ“ Saved charts, plots, wordclouds
â”‚   â””â”€â”€ topic_wordcloud.png 
â”‚
â”œâ”€â”€ models/                       # ğŸ“ Trained models, embeddings (to be added later)
â”‚
â”œâ”€â”€ requirements.txt              # ğŸ“„ Python package dependencies
â”‚
â””â”€â”€ README.md                     # ğŸ“„ Project documentation

```


## ğŸ“Š Key Analyses
- Exploratory Data Analysis (EDA)
- Topic Modeling using LDA
- Sentiment Analysis using TextBlob
- Named Entity Recognition (NER) with spaCy
- Clustering job descriptions using KMeans + UMAP/TSNE
- Trend Analysis of keywords, topics, sentiment over time
- Interactive Dashboard (Ipywidgets + Plotly)

## ğŸ“ˆ Business Insights
- Majority of ML jobs are posted in California and New York.
- Python, Machine Learning, Data Science are dominant keywords.
- Overall sentiment of postings is highly positive.
- Clustering reveals distinct job types such as Research, Engineering, Data Science.

## âš  Limitations
- Dataset is limited to 1,000 postings.
- No salary or benefits data.
- BERTopic not used due to environment restrictions (optional future work).

## ğŸš€ Future Enhancements
- Use BERTopic for dynamic topic modeling over time.
- Extract skill trends using NLP-powered skill extractors.
- Deploy interactive dashboard using Streamlit, Voila, or Panel.
- Predict emerging skill demand using forecasting models.

## ğŸ“š References
- HuggingFace Datasets
- Scikit-learn Documentation
- TextBlob Documentation
- SpaCy NER Models
- UMAP-learn for dimensionality reduction

## ğŸ¤ Acknowledgements
Thanks to all open-source contributors and dataset providers.
